# Master build management file for covid forecasting datasets.

##########
# CONFIG #
##########

# imports
import os
from pathlib import Path

# set master config file with paths and globals
configfile: 'config/config.yaml'

# this section ONLY ASSERTS the existence of these environment
# variables, it does not assign them to objects
envvars:
    "IEC",
    "IEC1",
    "TMP",
    "MBTOKEN_TILE"

# assign env vars to objects for use in the snakefile
MBTOKEN_TILE=os.environ['MBTOKEN_TILE']
TMP=os.path.expanduser(os.environ['TMP'])
IEC=os.path.expanduser(os.environ['IEC'])
IEC1=os.path.expanduser(os.environ['IEC1'])

# set paths, leveraging settings in the config file
CODE=os.path.expanduser(config['globals']['ccode'])
DATA=os.path.expanduser(config['globals']['cdata'])
TILESET_NAME=config['globals']['tileset_name']


#########
# RULES #
#########

# master rule to define the final output
rule all:
    input:
        f'{TMP}/covid_data.mbtiles',
        f'{TMP}/tileset_push.tkn',
        f'{TMP}/push_pred_data.tkn',
        f'{TMP}/test_merged_data.tkn'
        
# pull predicted data from google cloud
# rerun_indicator gets `touch`ed from cronjob to trigger pipeline execution
rule pull_predicted_data:
    input:
        f'{TMP}/rerun_indicator.txt',
        f'{CODE}/b/pull_predicted_data.sh',
        f'{CODE}/b/pull_predicted_data_helper.py'
    conda: 'config/forecasting.yaml'
    output: f'{TMP}/data_pull.tkn'
    shell: f'source {CODE}/b/pull_predicted_data.sh {CODE}/predictions_credential.json {CODE}/b/pull_predicted_data_helper.py {DATA}/all_rt_estimates > {{output}}'

# create tabular data tables of predicted variables (from Anup et al), identified to pc11 dists
# UPDATE TO WILDCARD CSVS
rule process_predicted_data:
    input:
        rules.pull_predicted_data.output,        
        f'{DATA}/all_rt_estimates/WB_district_Rt.csv',
        f'{CODE}/b/process_predicted_data.do'
    output:
        f'{DATA}/pred_data_district.dta',
        f'{DATA}/pred_data_state.dta',
        f'{DATA}/pred_data_district.csv',
        f'{DATA}/pred_data_state.csv',
        f'{DATA}/pred_data_rt_choropleth.dta',
    shell: f'stata -b {CODE}/b/process_predicted_data.do'

# create data tables for all other DDL covid data to display in district popups
rule process_ddl_data:
    input:
        f'{IEC}/covid/hospitals/pc_hospitals_dist.dta',
        f'{CODE}/b/process_ddl_data.do'
    output:
        f'{DATA}/ddl_data.dta',
    shell: f'stata -b {CODE}/b/process_ddl_data.do '

# merge DDL and predicted data
rule merge_ddl_pred_data:
    input:
        rules.process_predicted_data.output,        
        rules.process_ddl_data.output,        
        f'{CODE}/b/merge_ddl_pred_data.do'
    output:
        f'{DATA}/merged_data_district.dta',
    shell: f'stata -b {CODE}/b/merge_ddl_pred_data.do'

# creation of geojson from full tabular district data (all dates X rt, etc) for the plots
rule dist_data_to_geojson:
    input:
        rules.merge_ddl_pred_data.output,        
        f'{DATA}/district-simplified-mapshaper.shp',
        f'{CODE}/b/data_to_geojson.py'
    output:
        f'{DATA}/district.geojson'
    conda: 'config/forecasting_spatial.yaml'
    shell: f'python {CODE}/b/data_to_geojson.py --intable {rules.merge_ddl_pred_data.output} --inshp {DATA}/district-simplified-mapshaper.shp --outfile {{output}}'

# creation of geojson from latest Rt observation by district, for the choropleth
rule map_data_to_geojson:
    input:
        rules.process_predicted_data.output,        
        f'{DATA}/district-simplified-mapshaper.shp',
        f'{CODE}/b/data_to_geojson.py'
    output:
        f'{DATA}/district-map.geojson'
    conda: 'config/forecasting_spatial.yaml'
    shell: f'python {CODE}/b/data_to_geojson.py --intable {DATA}/pred_data_rt_choropleth.dta --inshp {DATA}/district-simplified-mapshaper.shp --outfile {{output}}'

# test basic data quality
rule test_merged_data:
    input:
        rules.merge_ddl_pred_data.output,        
        rules.dist_data_to_geojson.output,        
        f'{CODE}/b/test_merged_data.py'
    output:
        f'{TMP}/test_merged_data.tkn'
    conda: 'config/forecasting_spatial.yaml'
    shell: f'python {CODE}/b/test_merged_data.py &> {{output}}'

# push data for public access
rule push_public_data:
    input:
        rules.merge_ddl_pred_data.output,        
        rules.test_merged_data.output,        
        f'{CODE}/b/merge_ddl_pred_data.do'
    output:
        f'{TMP}/push_pred_data.tkn'
    shell: f'source {CODE}/b/push_public_data.sh > {{output}}'

# creation of vector tileset from geojson
rule create_vector_tileset:
    input:
        rules.test_merged_data.log,        
        rules.dist_data_to_geojson.output,
        rules.map_data_to_geojson.output,
        f'{CODE}/b/create_vector_tileset.sh'
    output: f'{TMP}/covid_data.mbtiles'
    shell: 'source {CODE}/b/create_vector_tileset.sh {rules.dist_data_to_geojson.output} {rules.map_data_to_geojson.output}'

# upload of mbtiles to mapbox studio
rule push_vector_tileset:
    input:
        rules.create_vector_tileset.output,
        f'{CODE}/b/push_vector_tileset.py'
    conda: 'config/forecasting.yaml'
    output: f'{TMP}/tileset_push.tkn'
    shell: f'python {CODE}/b/push_vector_tileset.py --file {rules.create_vector_tileset.output} --token {MBTOKEN_TILE} --tilesetname {TILESET_NAME} > {{output}}'

